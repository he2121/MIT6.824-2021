# 6.824 2020 Lecture 6: Raft (1)

## 内容

今天：Raft 选举 和日志处理（Lab：2A，2B）

下一节课：Raft 的持久性、客户行为、快照（实验室2C、2D）。

## 背景

### 我们已经见过容错系统中的一个模式

- MR 复制计算，但依靠单个 master 进行组织（lecture 1）
- GFS 复制数据，但依赖于单个 master 来选择主数据库 （lecture 3）
- VMware FT复制服务，但依赖于测试和设置来选择主服务（lecture 4）

所有这些都依赖于一个单一的实体来做出关键决策

好的地方: 单一实体的决策避免了脑裂

### 脑裂是如何产生的，为什么它是有害的?

假设我们正在复制一个测试和设置的服务，客户端请求将状态设置为1，服务器回复以前的状态。只有一个客户应该得到 "0 "的回复！！！

实际上它是一个锁，只有一个请求者能得到它。

分别有两个 client， server [c1,c2,s1,s2]

假设客户端 C1 可以联系副本 S1，但不能联系副本S2，C1是否应该只使用复制体 S1？

- 如果 S2 真的崩溃了，C1 必须在没有 S2 的情况下继续进行。否则，服务就不能容忍故障。
- 如果 S2 已经启动，但网络阻止了 C1与 S2 的联系。 C1不应该在没有 S2 的情况下进行。因为S2可能还活着并为客户C2服务

在这样的设置下，我们面临着一个讨厌的选择。

- 尽管有复制，但没有容错的能力
- 或由于脑裂，可能出现不正确的操作

### 问题所在：计算机无法区分 "服务器崩溃 "和 "网络故障"。

症状是一样的：对网络上的查询没有反应。

下面这种糟糕的情况常常被称为 "网络分区"。

- C1可以和 S1通信，C2 可以和 S2 通信
- 但 C1+S1与 C2+S2 是分开的

这一困难在很长一段时间内似乎是不可逾越的，似乎需要外部代理（人）来决定何时切入。

- 需要一个完全可靠的服务器（FT的测试和设置服务器）
- 或一个完全可靠的网络（所以 "无响应"=="崩溃"）。

但是，这些都是单点故障 -- 不可取的

能否有更好的办法？

### 应对网络分区的重大启示：多数人投票

- 需要奇数个服务器，例如 3 个
- 做任何事情都需要多数人的同意 -- 3人中的2人
- 为什么多数人投票帮助避免脑分？
  - 最多只能有一个分区拥有多数席位
  - 打破了我们看到的两个服务器的对称性
- 注意：大多数是指所有的服务器，而不仅仅是活的服务器。更广泛地说，2f+1 可以容忍 f 个失败的服务器，因为剩下的 f+1是 2f+1的大多数，如果超过 f 个失败（或无法联系到），则没有进展。
- 通常称为“法定人数”系统

- 多数人投票的一个关键特征是，Raft leader 选举的连续多数票中的服务器一定存在重叠，交集可以传递关于之前决策的信息

### 1990年左右发明了两种分区容忍的复制方案

- Paxos 和 View-Stamped Replication
- 在过去的15年中，这项技术在现实世界中得到了大量的应用
- Raft 文件是对现代技术的一个很好的介绍。

## Raft 概览

用 Raft 进行状态机复制--以实验3为例。

![image-20211230202151884](http://ganghuan.oss-cn-shenzhen.aliyuncs.com/img/image-20211230202151884-2021-12-30.png)

Raft 是每个副本中包含的一个库

时间线：

1. client 向 leader 的 K/V 层发送 `Put/Get` 命令
2. leader 在日志中添加命令
3. leader 向 followers 发送 `AppendEntries` RPCs
4. follower 在日志中添加命令
5. leader 等待大多数人（包括自己）的答复
6. 如果大多数人把它放在他们的日志中，该条目就是已提交。已提交的日志条目不会被丢失，即使出现故障
7. leader 执行命令，回复 client
8. 在下一个 `AppendEntries` 中 捎带提交信息
9. leader 说已提交，follower 就执行

### 为什么要写日志？

服务保持状态机的状态，例如，键/值DB。为什么这还不够？

- 日志使命令有顺序

  - 以帮助副本就执行顺序达成一致

  - 帮助 leader 确保 follower 有相同的日志

- 日志存储临时命令直到提交

- 日志持久地存储命令，以便在重新启动后重播

### 服务器的日志是彼此的精确副本吗?

不

- 有些副本可能会延迟，
- 我们会看到它们可以临时拥有不同的条目

好的方面

- 最终会一致
- 提交机制确保服务器只执行稳定的表项

### lab 2 Raft 接口

`rf.Start(command) (index, term, isleader)`

实验3 k/v 服务器的 `Put()/Get()` RPC处理程序调用 `Start()`

- `Start()`只对 Leader 有作用
- 在一个新的日志条目上开始 Raft 共识协议
  - 添加到 leader 日志
  - leader 发出 `AppendEntries` RPCs
  - `Start()` 直接返回，不需要等待 RPC 的回复
  - k/v 层的 `Put()/Get()` 必须等待提交，在 `applyCh` 上。
  - 如果服务在提交前失去了领导权，协议可能会失败。那么该命令可能会丢失，客户必须重新发送
  - 三个返回值：
    - isleader: false 如果这个服务器不是领导者，客户端应该尝试其他服务器。
    - term: currentTerm，帮助调用者检测领导者是否后来被降级
    - index: 要观察的日志条目，看命令是否被提交

`ApplyMsg`, 包括命令与其所在日志 index

- 每个 Raft 实例在 applyCh 上为每个已提交的日志条目发送一个 ApplyMsg。
- 每个 Raft 的本地上层应用执行命令，更新本地复制状态
- leader 向等待的客户 RPC 发送回复

### Raft的设计有两个主要部分

- 选举一个新的 Leader
- 确保在发生故障时仍有相同的日志

## Leader 选举

### 为什么需要 leader？

确保所有复制体以相同的顺序执行相同的命令(有些设计，如 Paxos，没有 Leader)

### Raft 按照 leader 计数

- 新 Leader-> 新任期
- 一个任期最多有一个领导人;也许没有领袖
- 这种计数方式可以帮助服务器追随最新的 leader，而不是追随已经被取代的领导者

### Raft 实例什么时候开始领袖选举?

- 当它一段时间内没有收到现任领导人要求“选举暂停”的消息时
- 增加本地 currentTerm，试图收集选票
- 注意:这可能会导致不必要的选举;这很慢但很安全
- 注:老 leader 可能还活着，并还认为自己是 leader

### 如何确保一个任期最多只有一位 leader?

(论文图2 RequestVote RPC和 server 规则)

- leader 必须得到来自大多数服务器的赞成投票
- 每个服务器每一任期只能投一票
  - 如果是 candidate，给自己投票
  - 不是 candidate，投票给第一个请求
- 对于一个给定的任期，最多一个服务器可以获得多数选票
  - 即使网络分区，最多也只能有一个 leader
  - 选举可以成功，即使一些服务器已经失败

### server如何知道新当选的 leader?

- 新 leader 获得了多数人的支持
- 其他人看到 `AppendEntries`心跳与更高的 term,
- 心跳抑制了任何新的选举

### 选举不可能成功有两个原因:

- 少于大多数的服务器可以到达/可用
- 候选人分票，无一过半

### Raft 如何避免票数分裂？

- 每个服务器选择一个随机的选举超时
- 随机性打破了服务器之间的对称性
- 最低超时时间有优先权, 希望有足够的时间在下一次到期前完成选举
- 其他人会看到新 leader 的 `AppendEntries`心跳，而不会成为候选人
- 随机化延迟是网络协议中的一种常见模式

### 如何选择选举超时？

- 至少有几个心跳间隔（以防网络丢掉一个心跳）以避免无谓的选举，这将浪费时间
- 随机部分的时间足以让一个候选人成功，然后再开始下一个
- 足够短的时间来对故障做出快速反应，避免长时间停顿
- 足够短的时间，允许在测试感到不安之前重试几次，测试要求在 5 秒或更短时间内完成选举

### 如果老 leader 不知道有新 leader 当选怎么办？

- 也许老 leader 没有看到选举信息
- 也许老 leader 是在少数人的网络分区中
- 新的 leader 意味着大多数的服务器已经增加了currentTerm
- 因此，老 leader（包括老任期）无法获得 AppendEntries 的多数
- 所以老 leader 不会提交或执行任何新的日志条目，因此不会产生脑裂
- 但少数可能接受老 leader 的AppendEntries，因此，在旧任期结束时，日志可能会出现偏差。